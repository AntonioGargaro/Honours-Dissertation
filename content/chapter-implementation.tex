% !TEX root = ../thesis-example.tex
%
\chapter{Implementation}
\label{sec:implementation}
%\vspace{-4em}{

The development of this web app can be split into three significant processes. The information and communications process which instated the backbone of controlling, gathering and communicating data. The bot process which is derived of three concurrent \textit{`actor'} models to gather and process Binance exchange data, then forwarding the generated signal results to the correct user. Finally, the front end process that can present information visually to an end user while allowing control over a bot's configurations and operations.

\section{Information \& Communication Process}
\label{sec:implementation:info_comm}

\noindent As stated in the aims of this project (Sec. \ref{sec:intro:aims}, pg. \pageref{sec:intro:aims}), the core services of the bot would be delivered as a web app using SaaS. The initial design choice of using a Flask web server was used to implement the communications backbone of the project. Extensions available to Flask allowed for extra functionality to be slotted into the web server. 

The extensions used include Flask-RESTful that allowed the implementation of a REST API, Flask-SocketIO that allowed streaming two way communication between the server and client using WebSockets, and lastly Flask-SQLAlchemy that allowed a lightweight SQLite database to store meta data for server management purposes. These extensions based off of Flask were used to make endpoints to retrieve Binance exchange data from, as well as communicating with running bots or creating new instances of one.

\subsection{Binance Exchange Data}
\label{sec:implementation:info_comm:binance_exchange_data}

% required to fulfil FR-3, FR-8, NFR-2

%\noindent The goal to developing the project's web server was to provide all endpoints for data requests in one place. This meant that, as well as allowing the developed front end UI to communicate with the web server, it is also open and available to all other software that can communicate with HTTP endpoints. 

\noindent During development, I initially discovered that modern browsers have security measures against directly requesting data that origins from external domains, such as \textit{http://api.binance.com}. This is used to prevent `Cross Site Scripting', that while not relevant to this project was an obstacle to developing this web app. A solution to this problem is to proxy the data requests through the web server that would forward the data with the correct configurations; as to let the web browser accept the incoming data. This restriction adheres to all request protocols except the WebSocket protocol, however to ensure consistency towards the origin point of accessing Binance's data, I also implemented WebSocket endpoints into the web server.

Both WebSockets and REST APIs were used to forward market data to the UI and the bot data gatherer (SOME REF HERE TO DATA GATHERER). The data endpoints I required that were offered by Binance were wrapped by Sam McHardy's \cite{MISC:Python-Binance} Python-Binance wrapper. This allowed for accessing this data through a function call that provided the required arguments to access a coin pair's data. (CODE SNIPPET REFERENCE SOMEWHERE).  The endpoints provided required data that is relevant towards candlestick charts, order books and basic overview data of all coin pairs.

Binance supplies two variations of candlestick chart data, a historical data retrieval through a fetch request and live streaming of new data through WebSockets. It could be an option to continually gather all the data solely from the API via fetch request, however Binance has added weight costs to accessing any REST endpoint. Firstly, this raises concerns of maxing out the servers total allowed weight limit within a given interval that would result in an IP ban and would severely disrupt the operation of the bot. Lastly, a fetch request gathers all historical data within an interval. After the first fetch request, the same data would be sent to the web server again apart from the latest interval potentially being updated. Hence, I opted to perform an initial fetch request, then connect to the WebSocket endpoint to stream new candlestick data thereafter. 

Binance provide documentation of what data to expect from their endpoints regarding both the REST API and WebSocket for candlestick data. Interestingly, the data is represented differently at either endpoint with the REST endpoint returning an array of arrays (CODE SNIPPET REFERENCE) and the WebSocket endpoint returning a dictionary object (CODE SNIPPET REFERENCE). For simplicity, the implemented web sever retrieves the data from both Binance endpoints and forwards this through a single WebSocket connection the user has made to the web server. This is done by the web server performing the fetch request to Binance and sending that to the user through it's own WebSocket connection. Then afterwards, starting its own WebSocket connection to Binance, mapping the dictionary to the fetch request format (SOME DATA REFERENCE) and forwarding the latest interval update to the user.

The use of streaming Binance data through their WebSockets was overlooked during the initial research phase for this project. As such, NFR-1 now has reduced significance as their is no weighting restrictions when using their WebSockets. However, as this project - in future iterations - intends to scale to serve multiple users, who on requesting candlestick data require an initial historic data request, an API restriction is used to prevent the web server's IP address from being banned. The API restriction works as the web server performs a \textit{self-ban} for the remainder of the warning interval when receiving a 429 status code from Binance. This status code signifies too many requests have been sent to Binance within the interval.

When the 429 status code triggers, the status code handler calculates when the next fetch request is allowed to be made. This is done by taking the millisecond time stamp the trigger occurred at, calculating where the start of this interval occurred at and then adding on the next minute. This can be seen at code snippet (REFERENCE CODE SNIPPET HERE). The calculated time would be added to a SQLite database stored on the web server so the restriction time could be accessible globally. At every API fetch to Binance a check of the current millisecond time being greater than the saved time in the database would occur. This process satisfies NFR-1 as receiving a 429 status code occurs when becoming close to the max weighting set at Binance.

Both order book and basic overview data of all coin pairs were also used in this project. As per the initial aims of this project the order book data endpoint was going to be utilised to find suitable entry into the market, however, due to time constraints these data endpoints are now used as additions to the UX on the front end UI. These endpoints were implemented differently from the candlestick chart data endpoints by having their own dedicated URL for REST requests and their own WebSocket endpoints. This is discussed in section (TODO UPDATE REF) \ref{sec:implementation:frontend}. As both endpoints retrieve data from Binance, the API restriction handler and check are utilised.
% ADD TESTING OF ALL 3 ENDPOINTS TO PROVE API RESTRICTION

\subsection{Bot Communication \& Management}
\label{sec:implementation:info_comm:bot_comm_management}

\noindent There is two REST endpoints implemented for controlling and configuring a bot. The first endpoint is used to start a bot by passing parameters such as the coin pair, the strategy ID being used, and the parameters for that strategy. This endpoint is wrapped in a WebSocket connection as the bot's signals are streamed to the front end UI. A second REST endpoint is used to stop an existing bot by sending its unique hash ID.

A hash ID is the response returned from the web server when successfully starting a bot. This provides a way to uniquely identify any bot in a machine readable way. Storing a bot to be communicated with on demand was a challenge as a bot only exists in the server's memory. There was no straightforward method to storing a reference to a bot in a database that can be used to control it at a later time. Therefore, a solution to this issue was to create an \textit{existence} model that would keep the memory references to a bot's \textit{manager} model that can be retrieved using hash IDs.

The bot \textit{manager} model is the hub that a user interacts with through starting and stopping the bot. This model manages one bot at a time, ensuring the bot process (SOME REF HERE) and dependencies are initialised correctly, there is a valid user session ID to forward the output too, and the bot is fully shutdown on a stop request. Designing this model allows for multiple bots to operate concurrently, while also allowing more than one strategy to operate simultaneously.

Stopping a bot requires sending the hash ID that is generated on its initialisation. This is accessed by a request to the REST endpoint that queries the \textit{existence} model. Checks are performed to return the correct status code. These checks are crucial to ensuring clarity about the systems current status by firstly confirming if the bot exists. If it doesn't exist, an appropriate response is returned so the UI can handle this correctly. If the bot does exist, then the bot is stopped and a further check is performed to see if it is stopped successfully. This approach is common throughout the system and allows multiple variations from responses to be returned. The UI can then handle this appropriately to keep the user updated about the outcome of requests.

\section{Bot Process}
\label{sec:implementation:bot}

\noindent As mentioned above, the bot process is built on \textit{actor} models for a non-blocking data flow. The initial design of this system was to have this process operate sequentially. However, during development the system would block until a certain process would complete. This raised issues, such as the gathering of Binance data missing updates as the intensive process of generating signals was being executed. This meant crucial data could be potentially missed which would lower the effectiveness of the bot.

% socketio client, listens to existing namespace, gets intial data then receives updates thereafter
The first stage of the process was to gather the exchange data to operate the bot. Initialising a WebSocket client that would connect and listen to the web server's stream of data was the simplest solution. This is because the client listens to the already implemented name-space that pushes the data to the front end UI and discussed in section \ref{sec:implementation:info_comm:binance_exchange_data} (Pg. \pageref{sec:implementation:info_comm:binance_exchange_data}). This ensured consistency between the data present on the front end UI and what the bot was processing, as well as reducing code duplication and testing. The WebSocket client library handles incoming data concurrently, so the actor model did not require implementation at this stage. The data gatherer actor simply listened for new incoming data, and forwarded it to the processing actor.

The actor model used for this process is based on an \textit{inbox} system. This is a queue that actors constantly check for new \textit{messages}. When a message is received it is popped from the queue and handled accordingly. This allows for other parts of the program to execute while the actor is waiting on messages. This couples the different processes of the system by the data flow being pushed to each actor in a non-blocking way as seen in figure \ref{fig:implementation:actor_dataflow} (Pg. \pageref{fig:implementation:actor_dataflow}). 

\begin{figure}[htb]
    \centering
	\includegraphics[width=0.9\textwidth]{content/graphics/diagrams/actor_dataflow.png}
	\caption{Data flow of the bot process: 
	\textit{(a)} The web server emits candlestick data to WebSocket client
	\textit{(b)} WebSocket client forwards data to actor 1's inbox
    \textit{(c)} Actor 1 pops data from inbox and parses data into pandas data structure
    \textit{(d)} Actor 1 executes chosen strategy using BackTrader and pushes signals to actor 2
    \textit{(e)} Actor 2 pops data from inbox passes to handler
    \textit{(f)} Actor 2 emits data to specific client}
    
	\label{fig:implementation:actor_dataflow}
\end{figure}

% data process, strategies, keeps data in memory, only updates

% signal handling process, emit to correct user





\section{Front End Process}
\label{sec:implementation:frontend}